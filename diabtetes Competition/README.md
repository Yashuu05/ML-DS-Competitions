# ðŸ©º Diabetes Probability Prediction â€” Kaggle Competition

This repository contains my work for the **Diabetes Prediction Competition** on Kaggle.  
The objective is to build a machine learning model that predicts the **probability of diagnosed diabetes** based on health indicators.

---

## ðŸš€ Competition Overview

| Detail | Information |
|--------|--------------|
| **Goal** | Predict the probability of diabetes for each individual in the test dataset |
| **Target Variable** | `diagnosed_diabetes` |
| **Evaluation Metric** | Area Under ROC Curve (AUC-ROC) |
| **Submission Format** | `id, diagnosed_diabetes` (probabilities, not classifications) |

---

## ðŸ“Š Dataset Information

The dataset used in this competition is synthetically generated from a deep learning model trained on the *Diabetes Health Indicators Dataset*.

- Distributions are similar â€” but not identical â€” to the original dataset.
- You may experiment using the original dataset to enhance results.

**Dataset Columns:**  
- Multiple health metrics & lifestyle indicators (BMI, Smoking, Alcohol consumption, Medical history, etc.)
- Target column: `diagnosed_diabetes` *(Training set only)*
- `Note : Due to rules and guidelines of Kaggle, Dataset is not included.`

---

## ðŸ“ Folder Structure

```
/ diabtets Competition
  |____ / Model  # includes saved model
          |___ LightGBM.pkl 
          |___ xgb_model.pkl
  |
  |____ / Notebook # Full Code
          |___ Diabetes.ipynb
  |
  |____ / Outputs # Outputs generated by saved models
          |___ submission.csv
          |___ submission_1.csv
```
---

## My Approach (Summary from Notebook)

### **1. Data Exploration**
- Checked missing values & feature distributions
- Compared correlations with `diagnosed_diabetes`
- Plotted key relationships to identify multicollinearity

### **2. Data Preprocessing**
- Standardized continuous features
- Label encoded / One-hot encoded necessary columns
- Trainâ€“validation split using `stratified sampling`

### **3. Modeling**
Models experimented with:
- **Logistic Regression (baseline)**
- **Random Forest Classifier**
- **XGBoost / LightGBM** *(best performance)*
Final model is selected based on **highest ROC-AUC on validation**.

---

### **4.  Evaluation**
- Tracked ROC-AUC as primary metric  
- Also checked:
  - Precisionâ€“Recall curve
  - Calibration of predicted probabilities
  - Feature importance (if model supports it)

---

### **5. Submission**
Generated predictions in required format:
```
id,diagnosed_diabetes
700000,0.2
700001,0.4
700002,0.5
etc.
```
---


---

## ðŸ§  Key Learnings
- How feature distributions affect model generalization.
- Working with probability predictions instead of hard classifications.
- Improving score with feature engineering and tuning.

---

## ðŸ“… Competition Timeline

| Stage | Date |
|-------|------|
| **Start Date** | December 1, 2025 |
| **Final Submission Deadline** | December 31, 2025 |
| **Team Merger Deadline** | December 31, 2025 |

---

## ðŸ› ï¸ Tech Stack

- Python, Jupyter Notebook
- Pandas, NumPy
- Scikit-learn
- XGBoost / LightGBM *(depending on final choice)*
- Matplotlib, Seaborn for visualization

---

## â­ Results & Next Steps
- Improve ROC-AUC via ensembling & stacking
- Test transfer learning from original NIH dataset
- Hyperparameter tuning with Optuna / GridSearchCV

---

> **This competition helps build practical ML intuition â€” especially around evaluation with probability-based targets and ROC-AUC scoring.**
